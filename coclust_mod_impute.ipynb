{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy.io as sio\n",
    "import scipy.sparse as sps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = './data'\n",
    "# mat = sio.loadmat(f'{data_dir}/binarydata.mat')\n",
    "# X = mat['X']\n",
    "# X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "    [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "    [0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "    [1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1],\n",
    "    [0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0],\n",
    "    [1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "    [0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0]])\n",
    "X = X[np.ix_([0, 2, 7, 1, 4, 8, 3, 5, 6],\n",
    "             [ 0,  4,  5, 15,  8,  9, 12, 13,  7, 10,  1,  2,  3,  6, 11, 14])]\n",
    "\n",
    "n_clusters = 3\n",
    "w = np.array([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 2, 2, 2, 2])\n",
    "z = np.array([0, 0, 0, 1, 1, 1, 2, 2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f1feb09ed68>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.spy(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_cells(X, n_out):\n",
    "    \"\"\"Given an n x r matrix X, returns n_out distinct cell positions\n",
    "    Parameters\n",
    "    ----------\n",
    "    X: np.ndarray or np.matrix, a 2D matrix\n",
    "    n_out: int, the number of cells to select.\n",
    "    \"\"\"\n",
    "    n, nc = X.size, X.shape[1]\n",
    "    choices = np.random.choice(n, size=n_out, replace=False)\n",
    "    rows = choices // nc\n",
    "    cols = choices % nc\n",
    "    return rows, cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0. nan  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [nan  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [nan  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1. nan nan  1.  1.]\n",
      " [ 0.  0.  0.  0. nan  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.]\n",
      " [nan  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1. nan  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  0.  0. nan  0.  0.  0.  0.  0.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. nan  0.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "r_nan, c_nan = random_cells(X, 10)\n",
    "res = X.astype(float)\n",
    "res[r_nan, c_nan] = np.nan\n",
    "print(np.isnan(res).sum())\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_labels = np.arange(n_clusters)[:, np.newaxis]\n",
    "w_labels = z_labels\n",
    "\n",
    "Z = (z == z_labels).T\n",
    "W = (w == w_labels).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  6,  0],\n",
       "       [ 0,  0, 18],\n",
       "       [20,  0,  0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def summarize_blocks(X, z, wT):\n",
    "    \"\"\"get the summary matrix from a contingency matrix X\n",
    "        with row labels z and column labels w\n",
    "    Parameters\n",
    "    ----------\n",
    "    X: np.array or np.matrix, n x d, contingency table (n rows d, columns)\n",
    "    z: np.array or np.matrix, n x k, row assignments (n rows, k classes)\n",
    "    wT: np.array or np.matrix, d x l, transpose of column assignments (d columns, l classes)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    for each block i,j return the sum of values in that block, shape k x l\n",
    "    \"\"\"\n",
    "    return z.T @ X @ wT\n",
    "\n",
    "summarize_blocks(X, Z, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[24,  6, 18],\n",
       "       [24,  6, 18],\n",
       "       [24,  6, 18]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_block_counts(z, wT):\n",
    "    \"\"\"get the count of item in each block of matrix X (n x d)\n",
    "    Parameters\n",
    "    ----------\n",
    "    z: np.array or np.matrix, n x k, row assignments (n rows, k classes)\n",
    "    wT: np.array or np.matrix, d x l, transpose of column assignments (d columns, l classes)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    for each block i,j return the number of items in that block, shape k x l\n",
    "    \"\"\"\n",
    "    return z.sum(axis=0)[:,np.newaxis] * wT.sum(axis=0)\n",
    "\n",
    "get_block_counts(Z, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        ],\n",
       "       [0.83333333, 0.        , 0.        ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_rep_vals = summarize_blocks(X, Z, W) / get_block_counts(Z, W)\n",
    "block_rep_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1. ]\n",
      " [1.  1.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [1.  1.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.8 0.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0. ]]\n"
     ]
    }
   ],
   "source": [
    "tmp = res.copy()\n",
    "tmp[r_nan, c_nan] = block_rep_vals[z[r_nan],w[c_nan]]\n",
    "print(np.round(tmp,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.   0.83 1.   0.   0.   0.   1.   0.   0.   1.  ]\n",
      "[0 0 1 0 0 0 1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(np.round(tmp[r_nan, c_nan],2))\n",
    "print(X[r_nan, c_nan])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.8 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]]\n"
     ]
    }
   ],
   "source": [
    "print(np.round(np.abs(X-tmp),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1. ]\n",
      " [1.  1.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [1.  1.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.5 0.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0. ]]\n"
     ]
    }
   ],
   "source": [
    "XW = X @ W\n",
    "# cls = np.argmax(XW, axis=1)\n",
    "# Z = cls == z_labels\n",
    "# print(XW)\n",
    "\n",
    "na_rep = XW / W.sum(axis=0)\n",
    "# print(np.round(na_rep,5))\n",
    "X_nan = res.copy()\n",
    "X_nan[r_nan, c_nan] = (na_rep @ W.T)[r_nan, c_nan]\n",
    "\n",
    "print(np.round(X_nan,1))\n",
    "\n",
    "# print(np.round(W.T @ na_rep,2).T[nan_mask])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.  0.5 1.  0.  0.  0.  1.  0.  0.  1. ]\n",
      "[0 0 1 0 0 0 1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(np.round(X_nan[r_nan, c_nan],2))\n",
    "print(X[r_nan, c_nan])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSE: 0.25\n",
      "rounded error matrix\n",
      "[[0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.5 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]]\n"
     ]
    }
   ],
   "source": [
    "diff = np.abs(X-X_nan)\n",
    "print(f\"SSE: {(diff**2).sum()}\")\n",
    "print(\"rounded error matrix\")\n",
    "print(np.round(diff,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1. ]\n",
      " [1.  1.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [1.  1.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.7 0.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0. ]]\n"
     ]
    }
   ],
   "source": [
    "XtZ = X.T @ Z\n",
    "\n",
    "na_rep = XtZ / Z.sum(axis=0)\n",
    "# print(np.round(na_rep,5))\n",
    "X_nan = res.copy()\n",
    "X_nan[r_nan, c_nan] = (Z @ na_rep.T)[r_nan, c_nan]\n",
    "\n",
    "print(np.round(X_nan,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.   0.67 1.   0.   0.   0.   1.   0.   0.   1.  ]\n",
      "[0 0 1 0 0 0 1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(np.round(X_nan[r_nan, c_nan],2))\n",
    "print(X[r_nan, c_nan])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSE: 0.4444444444444444\n",
      "rounded error matrix\n",
      "[[0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.7 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]]\n"
     ]
    }
   ],
   "source": [
    "diff = np.abs(X-X_nan)\n",
    "print(f\"SSE: {(diff**2).sum()}\")\n",
    "print(\"rounded error matrix\")\n",
    "print(np.round(diff,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modification de CoClustMod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "The :mod:`coclust.coclustering.coclust_mod` module provides an implementation\n",
    "of a co-clustering algorithm by direct maximization of graph modularity.\n",
    "\"\"\"\n",
    "\n",
    "# Author: Francois Role <francois.role@gmail.com>\n",
    "#         Stanislas Morbieu <stanislas.morbieu@gmail.com>\n",
    "\n",
    "# License: BSD 3 clause\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.utils import check_random_state, check_array\n",
    "from joblib import Parallel, delayed, effective_n_jobs\n",
    "\n",
    "from coclust.initialization import random_init\n",
    "from coclust.coclustering.base_diagonal_coclust import BaseDiagonalCoclust\n",
    "\n",
    "\n",
    "def _compute_modularity_matrix(X):\n",
    "    # Compute the modularity matrix\n",
    "    row_sums = np.matrix(X.sum(axis=1))\n",
    "    col_sums = np.matrix(X.sum(axis=0))\n",
    "    N = float(X.sum())\n",
    "    indep = (row_sums.dot(col_sums)) / N\n",
    "\n",
    "    # B is a numpy matrix\n",
    "    B = X - indep\n",
    "    return B, row_sums, col_sums, N\n",
    "\n",
    "\n",
    "def _compute_X_from_modularity_matrix(B, row_sums, col_sums, N):\n",
    "    X = B + row_sums @ col_sums / N\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fit_single(X, n_clusters, impute_fn, r_na, c_na, random_state, init, max_iter, tol, y=None):\n",
    "    \"\"\"Perform one run of co-clustering by direct maximization of graph\n",
    "    modularity.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : numpy array or scipy sparse matrix, shape=(n_samples, n_features)\n",
    "        Matrix to be analyzed\n",
    "    \"\"\"\n",
    "    if init is None:\n",
    "        W = random_init(n_clusters, X.shape[1], random_state)\n",
    "    else:\n",
    "        W = np.matrix(init, dtype=float)\n",
    "\n",
    "    Z = np.zeros((X.shape[0], n_clusters))\n",
    "\n",
    "    z_labels = np.arange(n_clusters)\n",
    "    w_labels = z_labels[:, np.newaxis]\n",
    "\n",
    "    B, row_sums, col_sums, N = _compute_modularity_matrix(X)\n",
    "\n",
    "    modularities = []\n",
    "\n",
    "    # Loop\n",
    "    m_begin = float(\"-inf\")\n",
    "    change = True\n",
    "    iteration = 0\n",
    "    while change:\n",
    "        change = False\n",
    "\n",
    "        # Reassign rows\n",
    "        BW = B.dot(W)\n",
    "        cls = np.argmax(BW, axis=1)\n",
    "        Z = cls == z_labels\n",
    "        # for idx, k in enumerate(np.argmax(BW, axis=1)):\n",
    "        #     Z[idx, :] = 0\n",
    "        #     Z[idx, k] = 1\n",
    "\n",
    "        # Update missing values in X using BW\n",
    "        # TODO: X = ....\n",
    "        B, row_sums, col_sums, N = _compute_modularity_matrix(X)\n",
    "\n",
    "        # Reassign columns\n",
    "        BtZ = (B.T).dot(Z)\n",
    "        cls = np.argmax(BtZ, axis=1)\n",
    "        W = cls == w_labels\n",
    "        # for idx, k in enumerate(np.argmax(BtZ, axis=1)):\n",
    "        #     W[idx, :] = 0\n",
    "        #     W[idx, k] = 1\n",
    "\n",
    "        # Update missing values in X using BtZ\n",
    "        # TODO: X = ....\n",
    "        B, row_sums, col_sums, N = _compute_modularity_matrix(X)\n",
    "\n",
    "        k_times_k = (Z.T).dot(BW)\n",
    "        m_end = np.trace(k_times_k)\n",
    "        iteration += 1\n",
    "        if (np.abs(m_end - m_begin) > tol and\n",
    "                iteration < max_iter):\n",
    "            modularities.append(m_end/N)\n",
    "            m_begin = m_end\n",
    "            change = True\n",
    "\n",
    "    row_labels_ = np.argmax(Z, axis=1).tolist()\n",
    "    column_labels_ = np.argmax(W, axis=1).tolist()\n",
    "    modularity = m_end / N\n",
    "    nb_iterations = iteration\n",
    "    return row_labels_,  column_labels_, modularity, modularities, nb_iterations, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoclustModImpute(BaseDiagonalCoclust):\n",
    "    \"\"\"Co-clustering by direct maximization of graph modularity.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_clusters : int, optional, default: 2\n",
    "        Number of co-clusters to form\n",
    "\n",
    "    init : numpy array or scipy sparse matrix, \\\n",
    "        shape (n_features, n_clusters), optional, default: None\n",
    "        Initial column labels\n",
    "\n",
    "    max_iter : int, optional, default: 20\n",
    "        Maximum number of iterations\n",
    "\n",
    "    n_init : int, optional, default: 1\n",
    "        Number of time the algorithm will be run with different\n",
    "        initializations. The final results will be the best output of `n_init`\n",
    "        consecutive runs in terms of modularity.\n",
    "\n",
    "    random_state : integer or numpy.RandomState, optional\n",
    "        The generator used to initialize the centers. If an integer is\n",
    "        given, it fixes the seed. Defaults to the global numpy random\n",
    "        number generator.\n",
    "\n",
    "    tol : float, default: 1e-9\n",
    "        Relative tolerance with regards to modularity to declare convergence\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    row_labels_ : array-like, shape (n_rows,)\n",
    "        Bicluster label of each row\n",
    "\n",
    "    column_labels_ : array-like, shape (n_cols,)\n",
    "        Bicluster label of each column\n",
    "\n",
    "    modularity : float\n",
    "        Final value of the modularity\n",
    "\n",
    "    modularities : list\n",
    "        Record of all computed modularity values for all iterations\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    * Ailem M., Role F., Nadif M., Co-clustering Document-term Matrices by \\\n",
    "    Direct Maximization of Graph Modularity. CIKM 2015: 1807-1810\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_clusters=2, init=None, max_iter=20, n_init=1,\n",
    "                 tol=1e-9, random_state=None, n_jobs=1):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.init = init\n",
    "        self.max_iter = max_iter\n",
    "        self.n_init = n_init\n",
    "        self.tol = tol\n",
    "        self.random_state = random_state\n",
    "        self.n_jobs = n_jobs\n",
    "        # to remove except for self.modularity = -np.inf!!!\n",
    "        self.row_labels_ = None\n",
    "        self.column_labels_ = None\n",
    "        self.modularity = -np.inf\n",
    "        self.modularities = []\n",
    "\n",
    "    def fit(self, X, impute_fn, y=None):\n",
    "        \"\"\"Perform co-clustering by direct maximization of graph modularity.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy array or scipy sparse matrix, shape=(n_samples, n_features)\n",
    "            Matrix to be analyzed\n",
    "        \"\"\"\n",
    "\n",
    "        random_state = check_random_state(self.random_state)\n",
    "\n",
    "        check_array(X, accept_sparse=True, dtype=\"numeric\", order=None,\n",
    "                    copy=False, force_all_finite=True, ensure_2d=True,\n",
    "                    allow_nd=False, ensure_min_samples=self.n_clusters,\n",
    "                    ensure_min_features=self.n_clusters,\n",
    "                    warn_on_dtype=False, estimator=None)\n",
    "\n",
    "        if type(X) == np.ndarray:\n",
    "            X = np.matrix(X)\n",
    "\n",
    "        X = X.astype(float)\n",
    "\n",
    "        X_ = X.copy()\n",
    "        r_na, c_na = np.where(np.isnan(X_))\n",
    "\n",
    "        modularity = self.modularity\n",
    "        modularities = []\n",
    "        row_labels = None\n",
    "        column_labels = None\n",
    "        seeds = random_state.randint(np.iinfo(np.int32).max, size=self.n_init)\n",
    "        if effective_n_jobs(self.n_jobs) == 1 or True:\n",
    "            for seed in seeds:\n",
    "                new_row_labels,  new_column_labels, new_modularity, new_modularities, new_nb_iterations, new_X_ = _fit_single(\n",
    "                    X_, self.n_clusters, impute_fn, r_na, c_na, seed, self.init, self.max_iter, self.tol, y)\n",
    "                if np.isnan(new_modularity):\n",
    "                    raise ValueError(\n",
    "                        \"matrix may contain unexpected NaN values\")\n",
    "                # remember attributes corresponding to the best modularity\n",
    "                if (new_modularity > modularity):\n",
    "                    modularity = new_modularity\n",
    "                    modularities = new_modularities\n",
    "                    row_labels = new_row_labels\n",
    "                    column_labels = new_column_labels\n",
    "                    X_ = new_X_\n",
    "        else:\n",
    "            results = Parallel(n_jobs=self.n_jobs, verbose=0)(\n",
    "                delayed(_fit_single)(X_, self.n_clusters, impute_fn, r_na, c_na,\n",
    "                                     seed, self.init, self.max_iter, self.tol, y)\n",
    "                for seed in seeds)\n",
    "            list_of_row_labels,  list_of_column_labels, list_of_modularity, list_of_modularities, list_of_nb_iterations, list_of_imputed = zip(\n",
    "                *results)\n",
    "            best = np.argmax(list_of_modularity)\n",
    "            row_labels = list_of_row_labels[best]\n",
    "            column_labels = list_of_column_labels[best]\n",
    "            modularity = list_of_modularity[best]\n",
    "            modularities = list_of_modularities[best]\n",
    "            n_iter = list_of_nb_iterations[best]\n",
    "\n",
    "        # update instance variables\n",
    "        self.modularity = modularity\n",
    "        self.modularities = modularities\n",
    "        self.row_labels_ = row_labels\n",
    "        self.column_labels_ = column_labels\n",
    "        self.X_ = X_\n",
    "\n",
    "        return self"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
